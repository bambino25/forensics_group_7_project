{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "220072bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "742d0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")\n",
    "default_path = DATA_DIR / \"data.csv\"\n",
    "war_related_path = DATA_DIR / \"data_war_related.csv\"\n",
    "war_related_ner_path = DATA_DIR / \"data_war_related_ner.csv\"\n",
    "\n",
    "# 1. Load the data --> data.csv, data_war_related.csv, data_war_related_ner.csv\n",
    "# 2. Handle missing values\n",
    "# 3. Handle DateTime columns\n",
    "# 6. Save the cleaned data to a new CSV file\n",
    "\n",
    "class Extract:\n",
    "    def __init__(self, default_path, war_related_path, war_related_ner_path):\n",
    "        self.default_path = default_path\n",
    "        self.war_related_path = war_related_path\n",
    "        self.war_related_ner_path = war_related_ner_path\n",
    "        \n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load the data from CSV files.\"\"\"\n",
    "        data = pd.read_csv(self.default_path, index_col=0)\n",
    "        war_related_data = pd.read_csv(self.war_related_path, index_col=0)\n",
    "        war_related_ner_data = pd.read_csv(self.war_related_ner_path, index_col=0)\n",
    "        \n",
    "        return data, war_related_data, war_related_ner_data\n",
    "    \n",
    "    \n",
    "extract = Extract(default_path, war_related_path, war_related_ner_path)\n",
    "df, war_related_df, war_related_ner_df = extract.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83f9b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed datetime to datetime format.\n",
      "Transformed datetime to datetime format.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 709 entries, 1 to 5861\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   people              498 non-null    object\n",
      " 1   organization        514 non-null    object\n",
      " 2   weapon              152 non-null    object\n",
      " 3   military_equipment  65 non-null     object\n",
      " 4   gun_types           4 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 33.2+ KB\n",
      "Transformed people to list format.\n",
      "Transformed organization to list format.\n",
      "Transformed weapon to list format.\n",
      "Transformed military_equipment to list format.\n",
      "Transformed gun_types to list format.\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform_to_datetime(self, df, date_col):\n",
    "        \"\"\"Convert date columns to datetime format.\"\"\"\n",
    "        if date_col in df.columns:\n",
    "            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "\n",
    "        # NaT values with the mean of the column\n",
    "        if df[date_col].isnull().any():\n",
    "            mean_date = df[date_col].mean()\n",
    "            df.fillna({date_col: mean_date}, inplace=True)\n",
    "            \n",
    "        print(f\"Transformed {date_col} to datetime format.\")\n",
    "        return df\n",
    "\n",
    "    def str_to_list(self, df, col: list):\n",
    "        \"\"\"Convert string representation of list to actual list.\"\"\"\n",
    "        for column in col:\n",
    "            if column in df.columns:\n",
    "                df[column] = df[column].apply(lambda x: [item.strip() for item in x.split(\",\") if item.strip()] if isinstance(x, str) else list())\n",
    "            print(f\"Transformed {column} to list format.\")\n",
    "        return df\n",
    "    def show_missing_values(self, df):\n",
    "        \"\"\"Show missing values in the dataframe.\"\"\"\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "df = preprocessor.transform_to_datetime(df, 'datetime')\n",
    "war_related_df = preprocessor.transform_to_datetime(war_related_df, 'datetime')\n",
    "war_related_ner_df.info()\n",
    "war_related_ner_df = preprocessor.str_to_list(war_related_ner_df, war_related_ner_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2291cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to  entity_count_over_time.csv\n"
     ]
    }
   ],
   "source": [
    "class Transformer:\n",
    "    def __init__(self, df, war_related_df, war_related_ner_df, target_dir = Path(\"./data/\")):\n",
    "        self.df = df\n",
    "        self.war_related_df = war_related_df\n",
    "        self.war_related_ner_df = war_related_ner_df\n",
    "        self.target_dir = target_dir\n",
    "\n",
    "    def kpi(self, name=\"KPI\"):\n",
    "        \"\"\"Calculate KPIs and return a dataframe with kpi_name and value.\"\"\"\n",
    "        # Calculate the number of unique sites examined\n",
    "        unique_sites = self.df[\"originFile\"].nunique()\n",
    "        \n",
    "        # Calculate the number of non-null posts\n",
    "        non_null_posts = self.df[\"messageContent\"].notnull().sum()\n",
    "        \n",
    "        # Create a dataframe with the results\n",
    "        result_df = pd.DataFrame({\n",
    "            \"kpi_name\": [\"Sites\", \"Posts\"],\n",
    "            \"value\": [unique_sites, non_null_posts]\n",
    "        })\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(result_df, name)\n",
    "\n",
    "    def posts_by_time(self, name=\"posts_by_time\"):\n",
    "        \"\"\"Calculate a dataframe from df with the number of posts (colname = count) by time (colname = date).\"\"\"\n",
    "        df['date'] = pd.to_datetime(df['datetime']).dt.date\n",
    "        posts_by_time = df.groupby('date').size().reset_index(name='count')\n",
    "        posts_by_time['date'] = pd.to_datetime(posts_by_time['date'])\n",
    "        posts_by_time.sort_values('date', inplace=True)\n",
    "        \n",
    "        # Fill gaps between the first and last date with 0\n",
    "        all_dates = pd.date_range(start=posts_by_time['date'].min(), \n",
    "                      end=posts_by_time['date'].max(), \n",
    "                      freq='D')\n",
    "        all_dates_df = pd.DataFrame({'date': all_dates})\n",
    "        posts_by_time = pd.merge(all_dates_df, posts_by_time, on='date', how='left').fillna(0)\n",
    "        posts_by_time['count'] = posts_by_time['count'].astype(int)\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(posts_by_time, name)\n",
    "\n",
    "\n",
    "    def posts_by_length(self, name=\"posts_by_length\"):\n",
    "        \"\"\"Calculate the number chars per post\"\"\"\n",
    "        df['length'] = df['messageContent'].str.len()\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(df['length'], name)\n",
    "\n",
    "    def dist_topic(self, name=\"dist_topic\"):\n",
    "        \"\"\"Calculate the distribution of topics in the dataframe.\"\"\"\n",
    "        # Assuming 'topic' is a column in df called threadId\n",
    "        topic_distribution = self.df['threadId'].value_counts().reset_index()\n",
    "        topic_distribution.columns = ['topic', 'count']\n",
    "        # Order the topics by count\n",
    "        topic_distribution.sort_values(by='count', ascending=False, inplace=True)\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(topic_distribution, name)\n",
    "    \n",
    "    def dist_war_related(self, name=\"dist_war_related\"):\n",
    "        \"\"\"Create a DataFrame containing all indexes with a column 'war_classified' (0 or 1).\"\"\"\n",
    "        # Create a set of indexes classified as war-related\n",
    "        war_related_indexes = set(self.war_related_df.index)\n",
    "        \n",
    "        # Add a column 'war_classified' to the main DataFrame\n",
    "        self.df['war_classified'] = self.df.index.map(lambda idx: 1 if idx in war_related_indexes else 0)\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(self.df[['war_classified']], name)\n",
    "\n",
    "    def dist_ner(self, name=\"dist_ner\"):\n",
    "        \"\"\" From all the not null values in the war_related_ner_df, create a DataFrame with the columns 'entity' and 'count'.\"\"\"\n",
    "        # Count the number of not null values in for each col in war_related_ner_df \n",
    "        non_null_counts = self.war_related_ner_df.notnull().sum()\n",
    "        null_counts = self.war_related_ner_df.isnull().sum()\n",
    "        \n",
    "        # Create a DataFrame with the results\n",
    "        result_df = pd.DataFrame({\n",
    "            'entity': non_null_counts.index,\n",
    "            'count': non_null_counts.values\n",
    "        })\n",
    "    \n",
    "        # Save the result to a CSV file\n",
    "        self.save(result_df, name)\n",
    "\n",
    "    def top10_ner(self, name=\"top10_ner\"):\n",
    "        \"\"\"Calculate the top 10 entities in the war_related_ner_df for each column. Careful the cell values are lists.\"\"\"\n",
    "        result_df = pd.DataFrame(data=[], columns=['entity', 'value', 'count'])\n",
    "\n",
    "        for column in self.war_related_ner_df.columns:\n",
    "            entity = column\n",
    "            # Count the number of occurrences of each entity in the column and keep top 10\n",
    "            counts = self.war_related_ner_df[column].explode().value_counts().sort_values(ascending=False).head(10)\n",
    "            # Create a DataFrame for the top 10 entities\n",
    "            top_10_df = pd.DataFrame({\n",
    "                'entity': entity,\n",
    "                'value': counts.index,\n",
    "                'count': counts.values\n",
    "            })\n",
    "            # Append the top 10 DataFrame to the result DataFrame\n",
    "            result_df = pd.concat([result_df, top_10_df], ignore_index=True)\n",
    "        # Save the result to a CSV file\n",
    "        self.save(result_df, name)\n",
    "\n",
    "    def entity_count_over_time(self, name=\"entity_count_over_time\"):\n",
    "        \"\"\"Merge the col datetime from war_related_df with the entity count from war_related_ner_df.\n",
    "        Then for each day list the entities as json strings with entity: count for each column in war_related_ner_df.\n",
    "        For days without any entity, give an empty json string.\n",
    "        \"\"\"\n",
    "        # Merge the \"datetime\" column from war_related_df to the war_related_ner_df using the index\n",
    "        merged_df = pd.merge(self.war_related_ner_df, self.war_related_df[['datetime']], left_index=True, right_index=True)\n",
    "        \n",
    "        # Convert datetime to date\n",
    "        merged_df['date'] = pd.to_datetime(merged_df['datetime']).dt.date\n",
    "        \n",
    "        # Initialize the result DataFrame with the date column\n",
    "        result_df = pd.DataFrame({'date': merged_df['date'].unique()})\n",
    "        result_df.sort_values('date', inplace=True)\n",
    "        \n",
    "        # Process each column in war_related_ner_df\n",
    "        for column in self.war_related_ner_df.columns:\n",
    "            # Group by date and count the occurrences of each entity\n",
    "            entity_counts = merged_df.groupby('date')[column].agg(\n",
    "                lambda x: x.explode().str.strip().value_counts().to_dict()\n",
    "            ).reset_index(name=column)\n",
    "            \n",
    "            # Merge the counts into the result DataFrame\n",
    "            result_df = pd.merge(result_df, entity_counts, on='date', how='left')\n",
    "        \n",
    "        # Fill missing dates with empty dictionaries\n",
    "        for column in self.war_related_ner_df.columns:\n",
    "            result_df[column] = result_df[column].apply(lambda x: x if isinstance(x, dict) else {})\n",
    "        \n",
    "        # Save the result to a CSV file\n",
    "        self.save(result_df, name)\n",
    "\n",
    "\n",
    "    def save(self, df, name):\n",
    "        \"\"\"Save the DataFrame to a CSV file.\"\"\"\n",
    "        if not self.target_dir.exists(): # Check if the target directory exists, if not create it\n",
    "            os.makedirs(self.target_dir)\n",
    "        name = name + \".csv\"\n",
    "        df.to_csv(self.target_dir / name  , index=True)\n",
    "        print(\"Data saved to \", name)\n",
    "\n",
    "transformer = Transformer(df, war_related_df, war_related_ner_df)\n",
    "#transformer.kpi()\n",
    "#transformer.posts_by_time()\n",
    "#transformer.posts_by_length()\n",
    "#transformer.dist_topic()\n",
    "#transformer.dist_war_related()\n",
    "#transformer.dist_ner()\n",
    "#transformer.top10_ner()\n",
    "transformer.entity_count_over_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a62d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
